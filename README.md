

### Goal: Analyze Abalone board game and find the proper initial setups 
> steps:
> 1.  Building the enviorment of board game.  
> 2.  Training model use Monte Carlo tree search(mcts) + reinforcement learning(RL).  
> 3.  Using existed initial setups to test our model’s accuracy.   
> 4.  Generate initial setup win rate is 50/50 which evaluated by trained model.

### 1.Enviorment:
> Board Indexing System
> Action Encoding and Classification
> Generating Legal Moves
> Applying an Action to the Game State

### 2.MCTS+RL:
> 2.1 Minimax
> > implement alpha-beta algorithm (depth = 4)
> > record the data of every step for behavior cloning

> 2.2 Behavior cloning
> > use the result of Minimax to pretrain CNN.

> 2.3 CNN
> > convolution Layer (channel = 4).
> > Linear Layer (Full Connect).

> 2.4 Policy network
> > structure of CNN.
> > generate a list of probability.
> > 
> > we use reinforcement learning to train policy network.
> > 
> > 2.4.1 let two policy networks play until the end.
> > 
> > 2.4.2 get the trajectory of the Player
> > 
> > 2.4.3 approximate policy gradients
> > 
> > 2.4.4 update policy network

> 2.5 Value network
> > CNN structure + Tanh to generate a output in[-1, 1].
> > Using the trajectory generated by trained policy network’s self playing
to train value network. Every state will be consider value = 1 if the 
final reward is 1 in training process

> 2.6 MCTS
> > 2.6.1 selection:select action base on score.
> > 
> > 2.6.2 rollout:using policy network self playing, get reward(-1 reward for defeat, 1 reward for victory), then update.
> > 
> > 2.6.3 backpropagation:write updated value to mcts.json file for next simulation.

